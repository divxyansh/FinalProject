# -*- coding: utf-8 -*-
"""Ensemble.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nwv3dHd_-KrlSWvOBPOMs8MX3hXHF6s0
"""

from google.colab import files
uploaded = files.upload()
print(uploaded)

# -*- coding: utf-8 -*-
"""enstack_nb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MAozeWCy_SwjwukKKMR1DKmV4uBtB1RI
"""

# Install necessary libraries
!pip install imbalanced-learn --quiet
!pip install tensorflow --quiet
!pip install pandas scikit-learn --quiet
!pip install scikeras --quiet

# Import required libraries
from sklearn.ensemble import StackingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Define classifiers
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression

# Load dataset
df = pd.read_csv('/content/ML-EdgeIIoT-dataset.csv')
df.dropna(inplace=True)
df.drop_duplicates(inplace=True)

print(df.shape)
print(df.describe())

"""# Data preprocessing"""

# Separate features and target

print("PREPROCESSING")
X = df.drop('Attack_type', axis=1)
y = df['Attack_type']

# Encode target labels
if y.dtype == 'object':
    le_y = LabelEncoder()
    y = le_y.fit_transform(y)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Handle non-numeric features
non_numeric_cols = X_train.select_dtypes(include=['object']).columns
for column in non_numeric_cols:
    if column == 'frame.time':
        try:
            X_train[column] = pd.to_datetime(X_train[column], errors='coerce')
            X_test[column] = pd.to_datetime(X_test[column], errors='coerce')
            X_train[column] = X_train[column].astype('int64') // 10**9
            X_test[column] = X_test[column].astype('int64') // 10**9
        except Exception as e:
            print(f"Dropping problematic column: {column}")
            X_train.drop(column, axis=1, inplace=True)
            X_test.drop(column, axis=1, inplace=True)
    else:
        le = LabelEncoder()
        combined = pd.concat([X_train[column], X_test[column]], axis=0).astype(str)
        le.fit(combined)
        X_train[column] = le.transform(X_train[column].astype(str))
        X_test[column] = le.transform(X_test[column].astype(str))

# Fill missing values
X_train.fillna(0, inplace=True)
X_test.fillna(0, inplace=True)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Ensemble Stacking- Meta Classifier:NB")

#Ensemble Stacking
# Define base classifiers
base_learners = [
    ('lr', LogisticRegression(max_iter=2000, random_state=42)),
    ('mlp', MLPClassifier(max_iter=500, random_state=42)),
    ('kNN', KNeighborsClassifier(n_neighbors=5))
]
# Define meta-classifier and stacking model
meta_classifier = GaussianNB()
stacked_model = StackingClassifier(estimators=base_learners, final_estimator=meta_classifier, cv=5)

print("Ensemble Stacking NB")

# Train and evaluate stacked model
stacked_model.fit(X_train, y_train)
y_pred = stacked_model.predict(X_test)

acc = accuracy_score(y_test, y_pred)
# Get classification report as dict
report = classification_report(y_test, y_pred, target_names=le_y.classes_, output_dict=True)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
labels = le_y.classes_

# Plot confusion matrix
fig, ax = plt.subplots(figsize=(12, 10))  # Adjust size as needed
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot(cmap='Blues', ax=ax, colorbar=True)

# Fix x-axis label alignment
ax.set_xticks(np.arange(len(labels)))
ax.set_xticklabels(labels, rotation=45, ha='right')  # Rotate and align
plt.title(f'Confusion Matrix - Meta-NB')
plt.tight_layout()
plt.savefig(f"NB Meta_confusion_matrix.tiff", dpi=300, format='tiff')
plt.show()

# Initialize list to collect per-class metrics
rows = []

# Collect FPRs, FNRs, and supports
fprs = []
fnrs = []
supports = []

for i, label in enumerate(labels):

      TP = cm[i, i]
      FN = cm.sum(axis=1)[i] - TP
      FP = cm.sum(axis=0)[i] - TP
      TN = cm.sum() - (TP + FP + FN)

      precision = report[label]["precision"]
      recall = report[label]["recall"]
      f1 = report[label]["f1-score"]
      support = report[label]["support"]

      fpr = FP / (FP + TN) if (FP + TN) > 0 else 0
      fnr = FN / (FN + TP) if (FN + TP) > 0 else 0

      fprs.append(fpr)
      fnrs.append(fnr)
      supports.append(support)

      rows.append({
        "Class": label,
        "Precision": round(precision, 4),
        "Recall": round(recall, 4),
        "F1-Score": round(f1, 4),
        "Support": int(support),
        "FPR": round(fpr, 4),
        "FNR": round(fnr, 4)
      })

# Compute macro and weighted averages for FPR and FNR
macro_fpr = np.mean(fprs)
macro_fnr = np.mean(fnrs)
weighted_fpr = np.average(fprs, weights=supports)
weighted_fnr = np.average(fnrs, weights=supports)

    # Add accuracy row
rows.append({
      "Class": "accuracy",
      "Precision": "-",
      "Recall": "-",
      "F1-Score": round(acc,4),
      "Support": int(report['accuracy'] * len(y_test)),
      "FPR": "-",
      "FNR": "-"
})

# Add macro avg row
rows.append({
        "Class": "macro avg",
        "Precision": round(report['macro avg']["precision"], 4),
        "Recall": round(report['macro avg']["recall"], 4),
        "F1-Score": round(report['macro avg']["f1-score"], 4),
        "Support": int(report['macro avg']["support"]),
        "FPR": round(macro_fpr, 4),
        "FNR": round(macro_fnr, 4)
})

# Add weighted avg row
rows.append({
        "Class": "weighted avg",
        "Precision": round(report['weighted avg']["precision"], 4),
        "Recall": round(report['weighted avg']["recall"], 4),
        "F1-Score": round(report['weighted avg']["f1-score"], 4),
        "Support": int(report['weighted avg']["support"]),
        "FPR": round(weighted_fpr, 4),
        "FNR": round(weighted_fnr, 4)
})

# Create DataFrame
results_df = pd.DataFrame(rows)

# Print table
print("Evaluation Metrics per Class:")
print(results_df.to_string(index=False))

# Save to CSV
results_df.to_csv('NB_Meta_classifier_summary.csv', index=False)
print("\n Results saved to ' NB_Meta_classifier_summary.csv'")

print("Ensemble Stacking NB")

# -*- coding: utf-8 -*-
"""enstack_nb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MAozeWCy_SwjwukKKMR1DKmV4uBtB1RI
"""

# Install necessary libraries
!pip install imbalanced-learn --quiet
!pip install tensorflow --quiet
!pip install pandas scikit-learn --quiet
!pip install scikeras --quiet

# Import required libraries
from sklearn.ensemble import StackingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Define classifiers
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression

# Load dataset
df = pd.read_csv('/content/ML-EdgeIIoT-dataset.csv')
df.dropna(inplace=True)
df.drop_duplicates(inplace=True)

print(df.shape)
print(df.describe())

"""# Data preprocessing"""

# Separate features and target

print("PREPROCESSING")
X = df.drop('Attack_type', axis=1)
y = df['Attack_type']

# Encode target labels
if y.dtype == 'object':
    le_y = LabelEncoder()
    y = le_y.fit_transform(y)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Handle non-numeric features
non_numeric_cols = X_train.select_dtypes(include=['object']).columns
for column in non_numeric_cols:
    if column == 'frame.time':
        try:
            X_train[column] = pd.to_datetime(X_train[column], errors='coerce')
            X_test[column] = pd.to_datetime(X_test[column], errors='coerce')
            X_train[column] = X_train[column].astype('int64') // 10**9
            X_test[column] = X_test[column].astype('int64') // 10**9
        except Exception as e:
            print(f"Dropping problematic column: {column}")
            X_train.drop(column, axis=1, inplace=True)
            X_test.drop(column, axis=1, inplace=True)
    else:
        le = LabelEncoder()
        combined = pd.concat([X_train[column], X_test[column]], axis=0).astype(str)
        le.fit(combined)
        X_train[column] = le.transform(X_train[column].astype(str))
        X_test[column] = le.transform(X_test[column].astype(str))

# Fill missing values
X_train.fillna(0, inplace=True)
X_test.fillna(0, inplace=True)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Ensemble Stacking- Meta Classifier:KNN")

#Ensemble Stacking
# Define base classifiers
base_learners = [
    ('LR', LogisticRegression(max_iter=2000, random_state=42)),
    ('mlp', MLPClassifier(max_iter=500, random_state=42)),
    ('NB', GaussianNB())
]
# Define meta-classifier and stacking model
meta_classifier = KNeighborsClassifier(n_neighbors=5)
stacked_model = StackingClassifier(estimators=base_learners, final_estimator=meta_classifier, cv=5)

print("Ensemble Stacking KNN")

# Train and evaluate stacked model
stacked_model.fit(X_train, y_train)
y_pred = stacked_model.predict(X_test)

acc = accuracy_score(y_test, y_pred)
# Get classification report as dict
report = classification_report(y_test, y_pred, target_names=le_y.classes_, output_dict=True)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
labels = le_y.classes_

# Plot confusion matrix
fig, ax = plt.subplots(figsize=(12, 10))  # Adjust size as needed
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot(cmap='Blues', ax=ax, colorbar=True)

# Fix x-axis label alignment
ax.set_xticks(np.arange(len(labels)))
ax.set_xticklabels(labels, rotation=45, ha='right')  # Rotate and align
plt.title(f'Confusion Matrix - Meta-k-NN')
plt.tight_layout()
plt.savefig(f"KNN Meta_confusion_matrix.tiff", dpi=300, format='tiff')
plt.show()

# Initialize list to collect per-class metrics
rows = []

# Collect FPRs, FNRs, and supports
fprs = []
fnrs = []
supports = []

for i, label in enumerate(labels):

      TP = cm[i, i]
      FN = cm.sum(axis=1)[i] - TP
      FP = cm.sum(axis=0)[i] - TP
      TN = cm.sum() - (TP + FP + FN)

      precision = report[label]["precision"]
      recall = report[label]["recall"]
      f1 = report[label]["f1-score"]
      support = report[label]["support"]

      fpr = FP / (FP + TN) if (FP + TN) > 0 else 0
      fnr = FN / (FN + TP) if (FN + TP) > 0 else 0

      fprs.append(fpr)
      fnrs.append(fnr)
      supports.append(support)

      rows.append({
        "Class": label,
        "Precision": round(precision, 4),
        "Recall": round(recall, 4),
        "F1-Score": round(f1, 4),
        "Support": int(support),
        "FPR": round(fpr, 4),
        "FNR": round(fnr, 4)
      })

# Compute macro and weighted averages for FPR and FNR
macro_fpr = np.mean(fprs)
macro_fnr = np.mean(fnrs)
weighted_fpr = np.average(fprs, weights=supports)
weighted_fnr = np.average(fnrs, weights=supports)

    # Add accuracy row
rows.append({
      "Class": "accuracy",
      "Precision": "-",
      "Recall": "-",
      "F1-Score": round(acc,4),
      "Support": int(report['accuracy'] * len(y_test)),
      "FPR": "-",
      "FNR": "-"
})

# Add macro avg row
rows.append({
        "Class": "macro avg",
        "Precision": round(report['macro avg']["precision"], 4),
        "Recall": round(report['macro avg']["recall"], 4),
        "F1-Score": round(report['macro avg']["f1-score"], 4),
        "Support": int(report['macro avg']["support"]),
        "FPR": round(macro_fpr, 4),
        "FNR": round(macro_fnr, 4)
})

# Add weighted avg row
rows.append({
        "Class": "weighted avg",
        "Precision": round(report['weighted avg']["precision"], 4),
        "Recall": round(report['weighted avg']["recall"], 4),
        "F1-Score": round(report['weighted avg']["f1-score"], 4),
        "Support": int(report['weighted avg']["support"]),
        "FPR": round(weighted_fpr, 4),
        "FNR": round(weighted_fnr, 4)
})

# Create DataFrame
results_df = pd.DataFrame(rows)

# Print table
print("Evaluation Metrics per Class:")
print(results_df.to_string(index=False))

# Save to CSV
results_df.to_csv('KNN_Meta_classifier_summary.csv', index=False)
print("\n Results saved to ' KNN_Meta_classifier_summary.csv'")

print("Ensemble Stacking KNN")

# -*- coding: utf-8 -*-
"""enstack_nb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MAozeWCy_SwjwukKKMR1DKmV4uBtB1RI
"""

# Install necessary libraries
!pip install imbalanced-learn --quiet
!pip install tensorflow --quiet
!pip install pandas scikit-learn --quiet
!pip install scikeras --quiet

# Import required libraries
from sklearn.ensemble import StackingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Define classifiers
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression

# Load dataset
df = pd.read_csv('/content/ML-EdgeIIoT-dataset.csv')
df.dropna(inplace=True)
df.drop_duplicates(inplace=True)

print(df.shape)
print(df.describe())

"""# Data preprocessing"""

# Separate features and target

print("PREPROCESSING")
X = df.drop('Attack_type', axis=1)
y = df['Attack_type']

# Encode target labels
if y.dtype == 'object':
    le_y = LabelEncoder()
    y = le_y.fit_transform(y)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Handle non-numeric features
non_numeric_cols = X_train.select_dtypes(include=['object']).columns
for column in non_numeric_cols:
    if column == 'frame.time':
        try:
            X_train[column] = pd.to_datetime(X_train[column], errors='coerce')
            X_test[column] = pd.to_datetime(X_test[column], errors='coerce')
            X_train[column] = X_train[column].astype('int64') // 10**9
            X_test[column] = X_test[column].astype('int64') // 10**9
        except Exception as e:
            print(f"Dropping problematic column: {column}")
            X_train.drop(column, axis=1, inplace=True)
            X_test.drop(column, axis=1, inplace=True)
    else:
        le = LabelEncoder()
        combined = pd.concat([X_train[column], X_test[column]], axis=0).astype(str)
        le.fit(combined)
        X_train[column] = le.transform(X_train[column].astype(str))
        X_test[column] = le.transform(X_test[column].astype(str))

# Fill missing values
X_train.fillna(0, inplace=True)
X_test.fillna(0, inplace=True)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Ensemble Stacking- Meta Classifier:LR")

#Ensemble Stacking
# Define base classifiers
base_learners = [
    ('MLP', MLPClassifier(max_iter=500, random_state=42)),
    ('NB', GaussianNB()),
    ('KNN', KNeighborsClassifier(n_neighbors=5))
]
# Define meta-classifier and stacking model
meta_classifier = LogisticRegression(max_iter=2000, random_state=42)
stacked_model = StackingClassifier(estimators=base_learners, final_estimator=meta_classifier, cv=5)

print("Ensemble Stacking LR")

# Train and evaluate stacked model
stacked_model.fit(X_train, y_train)
y_pred = stacked_model.predict(X_test)

acc = accuracy_score(y_test, y_pred)
# Get classification report as dict
report = classification_report(y_test, y_pred, target_names=le_y.classes_, output_dict=True)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
labels = le_y.classes_

# Plot confusion matrix
fig, ax = plt.subplots(figsize=(12, 10))  # Adjust size as needed
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot(cmap='Blues', ax=ax, colorbar=True)

# Fix x-axis label alignment
ax.set_xticks(np.arange(len(labels)))
ax.set_xticklabels(labels, rotation=45, ha='right')  # Rotate and align
plt.title(f'Confusion Matrix - Meta-LR')
plt.tight_layout()
plt.savefig(f"LR Meta_confusion_matrix.tiff", dpi=300, format='tiff')
plt.show()

# Initialize list to collect per-class metrics
rows = []

# Collect FPRs, FNRs, and supports
fprs = []
fnrs = []
supports = []

for i, label in enumerate(labels):

      TP = cm[i, i]
      FN = cm.sum(axis=1)[i] - TP
      FP = cm.sum(axis=0)[i] - TP
      TN = cm.sum() - (TP + FP + FN)

      precision = report[label]["precision"]
      recall = report[label]["recall"]
      f1 = report[label]["f1-score"]
      support = report[label]["support"]


      fpr = FP / (FP + TN) if (FP + TN) > 0 else 0
      fnr = FN / (FN + TP) if (FN + TP) > 0 else 0

      fprs.append(fpr)
      fnrs.append(fnr)
      supports.append(support)

      rows.append({
        "Class": label,
        "Precision": round(precision, 4),
        "Recall": round(recall, 4),
        "F1-Score": round(f1, 4),
        "Support": int(support),
        "FPR": round(fpr, 4),
        "FNR": round(fnr, 4)
      })

# Compute macro and weighted averages for FPR and FNR
macro_fpr = np.mean(fprs)
macro_fnr = np.mean(fnrs)
weighted_fpr = np.average(fprs, weights=supports)
weighted_fnr = np.average(fnrs, weights=supports)

    # Add accuracy row
rows.append({
      "Class": "accuracy",
      "Precision": "-",
      "Recall": "-",
      "F1-Score": round(acc,4),
      "Support": int(report['accuracy'] * len(y_test)),
      "FPR": "-",
      "FNR": "-"
})

# Add macro avg row
rows.append({
        "Class": "macro avg",
        "Precision": round(report['macro avg']["precision"], 4),
        "Recall": round(report['macro avg']["recall"], 4),
        "F1-Score": round(report['macro avg']["f1-score"], 4),
        "Support": int(report['macro avg']["support"]),
        "FPR": round(macro_fpr, 4),
        "FNR": round(macro_fnr, 4)
})

# Add weighted avg row
rows.append({
        "Class": "weighted avg",
        "Precision": round(report['weighted avg']["precision"], 4),
        "Recall": round(report['weighted avg']["recall"], 4),
        "F1-Score": round(report['weighted avg']["f1-score"], 4),
        "Support": int(report['weighted avg']["support"]),
        "FPR": round(weighted_fpr, 4),
        "FNR": round(weighted_fnr, 4)
})

# Create DataFrame
results_df = pd.DataFrame(rows)

# Print table
print("Evaluation Metrics per Class:")
print(results_df.to_string(index=False))

# Save to CSV
results_df.to_csv('LR_Meta_classifier_summary.csv', index=False)
print("\n Results saved to ' LR_Meta_classifier_summary.csv'")

print("Ensemble Stacking LR")

# -*- coding: utf-8 -*-
"""enstack_nb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MAozeWCy_SwjwukKKMR1DKmV4uBtB1RI
"""

# Install necessary libraries
!pip install imbalanced-learn --quiet
!pip install tensorflow --quiet
!pip install pandas scikit-learn --quiet
!pip install scikeras --quiet

# Import required libraries
from sklearn.ensemble import StackingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Define classifiers
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression

# Load dataset
df = pd.read_csv('/content/ML-EdgeIIoT-dataset.csv')
df.dropna(inplace=True)
df.drop_duplicates(inplace=True)

print(df.shape)
print(df.describe())

"""# Data preprocessing"""

# Separate features and target

print("PREPROCESSING")
X = df.drop('Attack_type', axis=1)
y = df['Attack_type']

# Encode target labels
if y.dtype == 'object':
    le_y = LabelEncoder()
    y = le_y.fit_transform(y)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Handle non-numeric features
non_numeric_cols = X_train.select_dtypes(include=['object']).columns
for column in non_numeric_cols:
    if column == 'frame.time':
        try:
            X_train[column] = pd.to_datetime(X_train[column], errors='coerce')
            X_test[column] = pd.to_datetime(X_test[column], errors='coerce')
            X_train[column] = X_train[column].astype('int64') // 10**9
            X_test[column] = X_test[column].astype('int64') // 10**9
        except Exception as e:
            print(f"Dropping problematic column: {column}")
            X_train.drop(column, axis=1, inplace=True)
            X_test.drop(column, axis=1, inplace=True)
    else:
        le = LabelEncoder()
        combined = pd.concat([X_train[column], X_test[column]], axis=0).astype(str)
        le.fit(combined)
        X_train[column] = le.transform(X_train[column].astype(str))
        X_test[column] = le.transform(X_test[column].astype(str))

# Fill missing values
X_train.fillna(0, inplace=True)
X_test.fillna(0, inplace=True)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Ensemble Stacking- Meta Classifier:MLP")

#Ensemble Stacking
# Define base classifiers
base_learners = [
    ('LR', LogisticRegression(max_iter=2000, random_state=42)),
    ('NB', GaussianNB()),
    ('KNN', KNeighborsClassifier(n_neighbors=5))
]
# Define meta-classifier and stacking model
meta_classifier = MLPClassifier(max_iter=500, random_state=42)
stacked_model = StackingClassifier(estimators=base_learners, final_estimator=meta_classifier, cv=5)

print("Ensemble Stacking MLP")

# Train and evaluate stacked model
stacked_model.fit(X_train, y_train)
y_pred = stacked_model.predict(X_test)

acc = accuracy_score(y_test, y_pred)
# Get classification report as dict
report = classification_report(y_test, y_pred, target_names=le_y.classes_, output_dict=True)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
labels = le_y.classes_

# Plot confusion matrix
fig, ax = plt.subplots(figsize=(12, 10))  # Adjust size as needed
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot(cmap='Blues', ax=ax, colorbar=True)

# Fix x-axis label alignment
ax.set_xticks(np.arange(len(labels)))
ax.set_xticklabels(labels, rotation=45, ha='right')  # Rotate and align
plt.title(f'Confusion Matrix - Meta-MLP')
plt.tight_layout()
plt.savefig(f"MLP Meta_confusion_matrix.tiff", dpi=300, format='tiff')
plt.show()

# Initialize list to collect per-class metrics
rows = []

# Collect FPRs, FNRs, and supports
fprs = []
fnrs = []
supports = []

for i, label in enumerate(labels):

      TP = cm[i, i]
      FN = cm.sum(axis=1)[i] - TP
      FP = cm.sum(axis=0)[i] - TP
      TN = cm.sum() - (TP + FP + FN)

      precision = report[label]["precision"]
      recall = report[label]["recall"]
      f1 = report[label]["f1-score"]
      support = report[label]["support"]


      fpr = FP / (FP + TN) if (FP + TN) > 0 else 0
      fnr = FN / (FN + TP) if (FN + TP) > 0 else 0

      fprs.append(fpr)
      fnrs.append(fnr)
      supports.append(support)

      rows.append({
        "Class": label,
        "Precision": round(precision, 4),
        "Recall": round(recall, 4),
        "F1-Score": round(f1, 4),
        "Support": int(support),
        "FPR": round(fpr, 4),
        "FNR": round(fnr, 4)
      })

# Compute macro and weighted averages for FPR and FNR
macro_fpr = np.mean(fprs)
macro_fnr = np.mean(fnrs)
weighted_fpr = np.average(fprs, weights=supports)
weighted_fnr = np.average(fnrs, weights=supports)

    # Add accuracy row
rows.append({
      "Class": "accuracy",
      "Precision": "-",
      "Recall": "-",
      "F1-Score": round(acc,4),
      "Support": int(report['accuracy'] * len(y_test)),
      "FPR": "-",
      "FNR": "-"
})

# Add macro avg row
rows.append({
        "Class": "macro avg",
        "Precision": round(report['macro avg']["precision"], 4),
        "Recall": round(report['macro avg']["recall"], 4),
        "F1-Score": round(report['macro avg']["f1-score"], 4),
        "Support": int(report['macro avg']["support"]),
        "FPR": round(macro_fpr, 4),
        "FNR": round(macro_fnr, 4)
})

# Add weighted avg row
rows.append({
        "Class": "weighted avg",
        "Precision": round(report['weighted avg']["precision"], 4),
        "Recall": round(report['weighted avg']["recall"], 4),
        "F1-Score": round(report['weighted avg']["f1-score"], 4),
        "Support": int(report['weighted avg']["support"]),
        "FPR": round(weighted_fpr, 4),
        "FNR": round(weighted_fnr, 4)
})

# Create DataFrame
results_df = pd.DataFrame(rows)

# Print table
print("Evaluation Metrics per Class:")
print(results_df.to_string(index=False))

# Save to CSV
results_df.to_csv('MLP_Meta_classifier_summary.csv', index=False)
print("\n Results saved to ' MLP_Meta_classifier_summary.csv'")

print("Ensemble Stacking MLP")